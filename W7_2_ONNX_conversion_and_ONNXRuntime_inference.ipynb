{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7La2SPkPHZKq"
      },
      "source": [
        "#### ONNX Test Conversion and ONNXRuntime Test Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq1ItP5g7hmt",
        "outputId": "ffab792b-adef-4059-a64f-392230c0ce4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.10/dist-packages (0.1.0.dev20240927)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.16.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.16->onnxscript) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Create and export the model to ONNX format\n",
        "!pip install onnx\n",
        "!pip install onnxscript\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Squeeze-and-Excite Module\n",
        "class SqueezeExcite(nn.Module):\n",
        "    def __init__(self, input_channels, squeeze_factor=4):\n",
        "        super(SqueezeExcite, self).__init__()\n",
        "        squeeze_channels = input_channels // squeeze_factor\n",
        "        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, 1)\n",
        "        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        scale = F.adaptive_avg_pool2d(x, 1)\n",
        "        scale = F.relu(self.fc1(scale))\n",
        "        scale = torch.sigmoid(self.fc2(scale))\n",
        "        return x * scale\n",
        "\n",
        "# Inverted Residual Block\n",
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion_factor, stride, use_se):\n",
        "        super(InvertedResidualBlock, self).__init__()\n",
        "        hidden_dim = in_channels * expansion_factor\n",
        "        self.use_residual = stride == 1 and in_channels == out_channels\n",
        "\n",
        "        self.expand = nn.Conv2d(in_channels, hidden_dim, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(hidden_dim)\n",
        "        self.depthwise = nn.Conv2d(hidden_dim, hidden_dim, 3, stride=stride, padding=1, groups=hidden_dim, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
        "        self.se = SqueezeExcite(hidden_dim) if use_se else nn.Identity()\n",
        "        self.project = nn.Conv2d(hidden_dim, out_channels, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.expand(x)))\n",
        "        out = F.relu(self.bn2(self.depthwise(out)))\n",
        "        out = self.se(out)\n",
        "        out = self.bn3(self.project(out))\n",
        "        if self.use_residual:\n",
        "            out = out + x\n",
        "        return out\n",
        "\n",
        "# MobileNetV3 Backbone\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1, bias=False),  # Initial stem conv layer\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            InvertedResidualBlock(16, 16, expansion_factor=1, stride=1, use_se=False),\n",
        "            InvertedResidualBlock(16, 24, expansion_factor=4, stride=2, use_se=False),\n",
        "            InvertedResidualBlock(24, 24, expansion_factor=4, stride=1, use_se=False),\n",
        "            InvertedResidualBlock(24, 40, expansion_factor=4, stride=2, use_se=True),\n",
        "            InvertedResidualBlock(40, 40, expansion_factor=4, stride=1, use_se=True),\n",
        "            InvertedResidualBlock(40, 80, expansion_factor=4, stride=2, use_se=False),\n",
        "            InvertedResidualBlock(80, 80, expansion_factor=4, stride=1, use_se=False),\n",
        "            InvertedResidualBlock(80, 112, expansion_factor=6, stride=1, use_se=True),\n",
        "            InvertedResidualBlock(112, 160, expansion_factor=6, stride=2, use_se=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(160, 1280, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1280, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# torch_model = MyModel()\n",
        "# torch_input = torch.randn(1, 1, 32, 32)\n",
        "# onnx_program = torch.onnx.dynamo_export(torch_model, torch_input) # Export from torch to onnx model format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDVI8BPh70KG",
        "outputId": "4bd8a747-5a19-44fe-ba93-296bdbbb3a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/passes/readability.py:54: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
            "  new_node = self.module.graph.get_attr(normalized_name)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node stem_1_running_mean target stem/1/running_mean stem/1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node stem_1_running_var target stem/1/running_var stem/1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn1_running_mean target layers/0/bn1/running_mean layers/0/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn1_running_var target layers/0/bn1/running_var layers/0/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn2_running_mean target layers/0/bn2/running_mean layers/0/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn2_running_var target layers/0/bn2/running_var layers/0/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn3_running_mean target layers/0/bn3/running_mean layers/0/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_0_bn3_running_var target layers/0/bn3/running_var layers/0/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn1_running_mean target layers/1/bn1/running_mean layers/1/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn1_running_var target layers/1/bn1/running_var layers/1/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn2_running_mean target layers/1/bn2/running_mean layers/1/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn2_running_var target layers/1/bn2/running_var layers/1/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn3_running_mean target layers/1/bn3/running_mean layers/1/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_1_bn3_running_var target layers/1/bn3/running_var layers/1/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn1_running_mean target layers/2/bn1/running_mean layers/2/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn1_running_var target layers/2/bn1/running_var layers/2/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn2_running_mean target layers/2/bn2/running_mean layers/2/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn2_running_var target layers/2/bn2/running_var layers/2/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn3_running_mean target layers/2/bn3/running_mean layers/2/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_2_bn3_running_var target layers/2/bn3/running_var layers/2/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn1_running_mean target layers/3/bn1/running_mean layers/3/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn1_running_var target layers/3/bn1/running_var layers/3/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn2_running_mean target layers/3/bn2/running_mean layers/3/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn2_running_var target layers/3/bn2/running_var layers/3/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn3_running_mean target layers/3/bn3/running_mean layers/3/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_3_bn3_running_var target layers/3/bn3/running_var layers/3/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn1_running_mean target layers/4/bn1/running_mean layers/4/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn1_running_var target layers/4/bn1/running_var layers/4/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn2_running_mean target layers/4/bn2/running_mean layers/4/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn2_running_var target layers/4/bn2/running_var layers/4/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn3_running_mean target layers/4/bn3/running_mean layers/4/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_4_bn3_running_var target layers/4/bn3/running_var layers/4/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn1_running_mean target layers/5/bn1/running_mean layers/5/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn1_running_var target layers/5/bn1/running_var layers/5/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn2_running_mean target layers/5/bn2/running_mean layers/5/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn2_running_var target layers/5/bn2/running_var layers/5/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn3_running_mean target layers/5/bn3/running_mean layers/5/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_5_bn3_running_var target layers/5/bn3/running_var layers/5/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn1_running_mean target layers/6/bn1/running_mean layers/6/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn1_running_var target layers/6/bn1/running_var layers/6/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn2_running_mean target layers/6/bn2/running_mean layers/6/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn2_running_var target layers/6/bn2/running_var layers/6/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn3_running_mean target layers/6/bn3/running_mean layers/6/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_6_bn3_running_var target layers/6/bn3/running_var layers/6/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn1_running_mean target layers/7/bn1/running_mean layers/7/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn1_running_var target layers/7/bn1/running_var layers/7/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn2_running_mean target layers/7/bn2/running_mean layers/7/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn2_running_var target layers/7/bn2/running_var layers/7/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn3_running_mean target layers/7/bn3/running_mean layers/7/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_7_bn3_running_var target layers/7/bn3/running_var layers/7/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn1_running_mean target layers/8/bn1/running_mean layers/8/bn1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn1_running_var target layers/8/bn1/running_var layers/8/bn1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn2_running_mean target layers/8/bn2/running_mean layers/8/bn2/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn2_running_var target layers/8/bn2/running_var layers/8/bn2/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn3_running_mean target layers/8/bn3/running_mean layers/8/bn3/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
            "/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py:1545: UserWarning: Node layers_8_bn3_running_var target layers/8/bn3/running_var layers/8/bn3/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
            "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.10/dist-packages (0.1.0.dev20240927)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.16.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.16->onnxscript) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Save the ONNX model in a file\n",
        "\n",
        "# Define model and export the Torch model to onnx format\n",
        "torch_model = MyModel()\n",
        "torch_model.eval() # Set the model to evaluation mode\n",
        "torch_input = torch.randn(1, 1, 32, 32)\n",
        "onnx_program = torch.onnx.dynamo_export(torch_model, torch_input)\n",
        "onnx_program.save(\"my_image_classifier.onnx\")\n",
        "\n",
        "# Import library and load from ONNX side\n",
        "!pip install onnx\n",
        "!pip install onnxscript\n",
        "import onnx\n",
        "onnx_model = onnx.load(\"my_image_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ngln9bG7w_e",
        "outputId": "3131ad05-82ef-4cea-fcd6-0b871821cf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.19.2\n",
            "Input length: 1\n",
            "Sample input: (tensor([[[[-0.2857, -0.6512,  1.3662,  ...,  0.3110, -0.3055,  0.9987],\n",
            "          [ 2.3651, -1.1885,  0.4880,  ...,  0.6857, -0.4443, -0.1408],\n",
            "          [ 0.3567,  0.0817,  0.5093,  ...,  0.7761, -0.7326, -0.0283],\n",
            "          ...,\n",
            "          [ 1.1313,  0.0174,  1.0204,  ...,  0.4647, -0.4251,  0.4863],\n",
            "          [ 1.6365,  0.9212, -1.3857,  ..., -0.5792,  0.9881, -2.1660],\n",
            "          [-1.0736, -0.2664, -0.1807,  ...,  0.1175, -1.0930,  0.3750]]]]),)\n",
            "\n",
            "\n",
            "PyTorch and ONNX Runtime output matched!\n",
            "\n",
            "\n",
            "PyTorch Output length: 1\n",
            "PyTorch Sample Output: tensor([[-0.0352,  0.0295,  0.0053,  0.0243,  0.0360, -0.0077,  0.0515,  0.0039,\n",
            "         -0.0066, -0.0568]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "ONNXRuntime Output length: 1\n",
            "ONNXRuntime Sample output: [array([[-0.03523888,  0.02945375,  0.00534764,  0.02429227,  0.03596256,\n",
            "        -0.00773817,  0.05146694,  0.00391704, -0.00663548, -0.05681039]],\n",
            "      dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "# Execute the ONNX model with ONNX Runtime\n",
        "# !pip install onnxruntime\n",
        "!pip install onnxruntime-gpu\n",
        "import onnxruntime\n",
        "onnx_input = onnx_program.adapt_torch_inputs_to_onnx(torch_input)\n",
        "print(f\"Input length: {len(onnx_input)}\")\n",
        "print(f\"Sample input: {onnx_input}\")\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"./my_image_classifier.onnx\", providers=['CPUExecutionProvider'])\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)\n",
        "\n",
        "\n",
        "# Compare the PyTorch results with the ones from the ONNX Runtime\n",
        "torch_outputs = torch_model(torch_input)\n",
        "torch_outputs = onnx_program.adapt_torch_outputs_to_onnx(torch_outputs)\n",
        "\n",
        "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
        "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
        "    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n",
        "\n",
        "print(\"\\n\\nPyTorch and ONNX Runtime output matched!\")\n",
        "print(f\"\\n\\nPyTorch Output length: {len(torch_output)}\")\n",
        "print(f\"PyTorch Sample Output: {torch_output}\")\n",
        "print(f\"\\n\\nONNXRuntime Output length: {len(onnxruntime_outputs)}\")\n",
        "print(f\"ONNXRuntime Sample output: {onnxruntime_outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZnQeymWHRxR"
      },
      "source": [
        "----\n",
        "#### Model Runtime Test with 1000 Samples Iteration (Non-opt FP32, Opt FP32, Opt FP16 [Half-Floating])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oKmTxdw-pIyQ"
      },
      "outputs": [],
      "source": [
        "input_shape = (1, 1, 32, 32)\n",
        "input_data_for_inference = torch.randn(input_shape, dtype=torch.float32).cuda()\n",
        "input_data_for_inference_fp16 = input_data_for_inference.to(dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7S8JM4D8z-u",
        "outputId": "0e1b488e-b1ce-49e9-fb53-ab3398d97c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-optimizing FP32 bench testing...\n",
            "PyTorch FPS: 216.49\n",
            "\n",
            "\n",
            "ONNXRuntime [FP32] Output length: 1\n",
            "ONNXRuntime [FP32] Sample output: tensor([[-0.0054,  0.0065, -0.0290,  0.0145, -0.0296, -0.0340,  0.0021,  0.0024,\n",
            "          0.0354, -0.0008]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "ONNXRuntime [FP32] Sample output type: torch.float32\n"
          ]
        }
      ],
      "source": [
        "# @title Non-Optimized FP32 (Full Tensor)\n",
        "import time\n",
        "\n",
        "input_shape = (1, 1, 32, 32)\n",
        "output_shape = (1, 10)\n",
        "\n",
        "#>>>> batch runs session\n",
        "print(\"Non-optimizing FP32 bench testing...\")\n",
        "#---Non-optimized---\n",
        "nonopt_model = MyModel().cuda().eval()\n",
        "num_iterations = 10000\n",
        "total_time = 0.0\n",
        "with torch.no_grad():\n",
        "    for i in range(num_iterations):\n",
        "        start_time = time.time()\n",
        "        input_data = torch.randn(input_shape).cuda()\n",
        "        output_data = nonopt_model(input_data)\n",
        "        end_time = time.time()\n",
        "        total_time += end_time - start_time\n",
        "pytorch_fps = num_iterations / total_time\n",
        "print(f\"PyTorch FPS: {pytorch_fps:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "#---------Inference with FP32--------------\n",
        "import onnxruntime as ort\n",
        "# Load the ONNX model and run inference\n",
        "# session = ort.InferenceSession('my_image_classifier_fp16.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "# onnx_input = onnx_program.adapt_torch_inputs_to_onnx(torch_input)\n",
        "# onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "\n",
        "output_data = nonopt_model(input_data_for_inference)\n",
        "\n",
        "print(f\"\\n\\nONNXRuntime [FP32] Output length: {len(output_data)}\")\n",
        "print(f\"ONNXRuntime [FP32] Sample output: {output_data}\")\n",
        "print(f\"ONNXRuntime [FP32] Sample output type: {output_data.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnANZLhs91Nl",
        "outputId": "6e8372c4-7333-431a-f846-c3a63ac113f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized model FP32 bench testing...\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "start inferencing...FP32\n",
            "Tensor FPS [FP32]: 373.14\n",
            "Speedup: 1.72x\n",
            "\n",
            "\n",
            "ONNXRuntime [FP32] Output length: 1\n",
            "ONNXRuntime [FP32] Sample output: [[-0.03523889  0.02945375  0.00534764  0.02429228  0.03596256 -0.00773814\n",
            "   0.05146693  0.00391703 -0.00663549 -0.05681043]]\n",
            "ONNXRuntime [FP32] Sample output type: float32\n"
          ]
        }
      ],
      "source": [
        "# @title Optimized FP32 (Full Tensor)\n",
        "import os\n",
        "os.environ[\"ALLOW_RELEASED_ONNX_OPSET_ONLY\"] = \"0\"\n",
        "import onnxruntime.backend as backend\n",
        "\n",
        "print(\"Optimized model FP32 bench testing...\")\n",
        "# Create a engine from the ONNX model and measure inference speed\n",
        "model_onnx = onnx.load('./my_image_classifier.onnx')\n",
        "onnx_engine = backend.prepare(model_onnx, device='GPU')\n",
        "num_iterations = 10000\n",
        "total_time_fp32 = 0.0\n",
        "print(\"start inferencing...FP32\")\n",
        "with torch.no_grad():\n",
        "    for i in range(num_iterations):\n",
        "        input_data = torch.randn(input_shape).cuda()\n",
        "        start_time = time.time()\n",
        "        output_data = onnx_engine.run(input_data.cpu().numpy())[0]\n",
        "        end_time = time.time()\n",
        "        total_time_fp32 += end_time - start_time\n",
        "tensor_fps_fp32 = num_iterations /total_time_fp32\n",
        "#tensor_fps = num_iterations / total_time\n",
        "print(f\"Tensor FPS [FP32]: {tensor_fps_fp32:.2f}\")\n",
        "print(f\"Speedup: {tensor_fps_fp32/pytorch_fps:.2f}x\")\n",
        "\n",
        "\n",
        "#---------Inference with FP16--------------\n",
        "import onnxruntime as ort\n",
        "# Load the ONNX model and run inference\n",
        "# session = ort.InferenceSession('my_image_classifier_fp16.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "# onnx_input = onnx_program.adapt_torch_inputs_to_onnx(torch_input)\n",
        "# onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "\n",
        "output_data = onnx_engine.run(input_data_for_inference.cpu().numpy())[0]\n",
        "\n",
        "print(f\"\\n\\nONNXRuntime [FP32] Output length: {len(output_data)}\")\n",
        "print(f\"ONNXRuntime [FP32] Sample output: {output_data}\")\n",
        "print(f\"ONNXRuntime [FP32] Sample output type: {output_data.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "272MZmQhBFqD",
        "outputId": "67f33b03-3893-4869-ae4c-deac4986e904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized model FP16 bench testing...\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "start inferencing...FP16\n",
            "Tensor FPS [FP16]: 413.97\n",
            "Speedup: 1.91x\n",
            "\n",
            "\n",
            "ONNXRuntime [FP16] Output length: 1\n",
            "ONNXRuntime [FP16] Sample output: [[-0.03525   0.02946   0.005344  0.02429   0.03595  -0.007744  0.05145\n",
            "   0.003918 -0.006638 -0.05682 ]]\n",
            "ONNXRuntime [FP16] Sample output type: float16\n"
          ]
        }
      ],
      "source": [
        "# @title Optimized FP16 (Half Tensor)\n",
        "print(\"Optimized model FP16 bench testing...\")\n",
        "\n",
        "# Try using CUDAExecutionProvider and check if it's available\n",
        "# ort_session = onnxruntime.InferenceSession(\"./my_image_classifier.onnx\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "\n",
        "torch_model_fp16 = torch_model.half()\n",
        "dummy_input_fp16 = torch.randn(input_shape, dtype=torch.float16)\n",
        "input_names = ['input']\n",
        "output_names = ['output']\n",
        "torch.onnx.export(torch_model_fp16, dummy_input_fp16, './my_image_classifier_fp16.onnx', verbose=False, input_names=input_names, output_names=output_names)\n",
        "\n",
        "#onnx_model_path_fp16 = f'outputs/{opt[\"compressed_directory\"]}/compressed_student_net_fp16.onnx'\n",
        "#session_fp16 = ort.InferenceSession(onnx_model_path_fp16, providers=providers)\n",
        "\n",
        "# Create a engine from the ONNX model and measure inference speed\n",
        "model_onnx_fp16 = onnx.load('./my_image_classifier_fp16.onnx')\n",
        "onnx_engine_fp16 = backend.prepare(model_onnx_fp16, device='GPU', provider='CUDAExecutionProvider', float16=True)\n",
        "\n",
        "num_iterations = 10000\n",
        "total_time_fp16 = 0.0\n",
        "print(\"start inferencing...FP16\")\n",
        "with torch.no_grad():\n",
        "    for i in range(num_iterations):\n",
        "        input_data = torch.randn(input_shape, dtype=torch.float16).cuda()\n",
        "        start_time = time.time()\n",
        "        output_data = onnx_engine_fp16.run(input_data.cpu().numpy())[0]\n",
        "        end_time = time.time()\n",
        "        total_time_fp16 += end_time - start_time\n",
        "tensor_fps_fp16 = num_iterations /total_time_fp16\n",
        "#tensor_fps = num_iterations / total_time\n",
        "print(f\"Tensor FPS [FP16]: {tensor_fps_fp16:.2f}\")\n",
        "print(f\"Speedup: {tensor_fps_fp16/pytorch_fps:.2f}x\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------Inference with FP16--------------\n",
        "import onnxruntime as ort\n",
        "# Load the ONNX model and run inference\n",
        "# session = ort.InferenceSession('my_image_classifier_fp16.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "# onnx_input = onnx_program.adapt_torch_inputs_to_onnx(torch_input)\n",
        "# onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "# input_data = torch.randn(input_shape, dtype=torch.float16).cuda()\n",
        "output_data = onnx_engine_fp16.run(input_data_for_inference_fp16.cpu().numpy())[0]\n",
        "\n",
        "print(f\"\\n\\nONNXRuntime [FP16] Output length: {len(output_data)}\")\n",
        "print(f\"ONNXRuntime [FP16] Sample output: {output_data}\")\n",
        "print(f\"ONNXRuntime [FP16] Sample output type: {output_data.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDCPGyulR7jN",
        "outputId": "859118d9-4425-4134-9870-dc7076ab412c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "Tensor FPS [INT8]: 406.70\n",
            "Speedup: 1.88x\n",
            "\n",
            "\n",
            "ONNXRuntime [INT8] Output length: 1\n",
            "ONNXRuntime [INT8] Sample output: [[-0.03523889  0.02945375  0.00534764  0.02429228  0.03596256 -0.00773814\n",
            "   0.05146693  0.00391703 -0.00663549 -0.05681043]]\n",
            "ONNXRuntime [INT8] Sample output type: float32\n"
          ]
        }
      ],
      "source": [
        "# @title Optimized and Compressed (Quantization) to support INT8\n",
        "import torch\n",
        "import torch.quantization\n",
        "\n",
        "#------------Quantize only in torch package---------------\n",
        "\"\"\"\n",
        "# Load your model\n",
        "torch_model = MyModel()  # Your model loading code here\n",
        "\n",
        "# Switch the model to evaluation mode\n",
        "torch_model.eval()\n",
        "\n",
        "# Fuse layers if necessary\n",
        "model_int8 = torch.quantization.fuse_modules(torch_model, [['conv1', 'relu1'],\n",
        "                                                           ['conv2', 'relu2']])\n",
        "\n",
        "# Apply quantization transformations\n",
        "model_int8.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "torch.quantization.prepare(model_int8, inplace=True)\n",
        "\n",
        "\n",
        "# Convert the model to a quantized version\n",
        "torch.quantization.convert(model_int8, inplace=True)\n",
        "\n",
        "# Save the quantized model\n",
        "torch.save(model_int8.state_dict(), 'quantized_model_int8.pth')\n",
        "\"\"\"\n",
        "#---------Quantize and convert to ONNX format--------------\n",
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "# Load the full precision ONNX model\n",
        "# model_fp32 = onnx.load('full_precision_model.onnx')\n",
        "\n",
        "# Apply dynamic quantization to INT8\n",
        "model_int8 = quantize_dynamic(\n",
        "    'my_image_classifier.onnx',\n",
        "    'my_quantized_classifier_int8.onnx',\n",
        "    weight_type=QuantType.QInt8  # You can use QuantType.QUInt8 for unsigned INT8\n",
        ")\n",
        "#---------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a engine from the ONNX model and measure inference speed\n",
        "model_onnx_int8 = onnx.load('./my_quantized_classifier_int8.onnx')\n",
        "onnx_engine_int8 = backend.prepare(model_onnx_int8, device='GPU', provider='CUDAExecutionProvider', float16=True)\n",
        "\n",
        "# Run a calibration step to collect statistics\n",
        "num_iterations = 10000\n",
        "total_time_int8 = 0.0\n",
        "with torch.no_grad():\n",
        "    for i in range(num_iterations):\n",
        "        input_data = torch.randn(input_shape, dtype=torch.float32).cuda()\n",
        "        start_time = time.time()\n",
        "        output_data = onnx_engine_int8.run(input_data.cpu().numpy())[0]\n",
        "        end_time = time.time()\n",
        "        total_time_int8 += end_time - start_time\n",
        "tensor_fps_int8 = num_iterations /total_time_int8\n",
        "#tensor_fps = num_iterations / total_time\n",
        "print(f\"Tensor FPS [INT8]: {tensor_fps_int8:.2f}\")\n",
        "print(f\"Speedup: {tensor_fps_int8/pytorch_fps:.2f}x\")\n",
        "\n",
        "#---------Inference with INT8--------------\n",
        "import onnxruntime as ort\n",
        "# Load the ONNX model\n",
        "\n",
        "# Load the ONNX model and run inference\n",
        "# session = ort.InferenceSession('my_quantized_classifier_int8.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "# input_data = torch.randn(input_shape, dtype=torch.float32).cpu().numpy()\n",
        "# output_quan_oxrun = session.run(None, {'l_x_': onnxruntime_input})[0]\n",
        "# onnx_input = onnx_program.adapt_torch_inputs_to_onnx(torch_input)\n",
        "# onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "# output_quan_oxrun = session.run(None, onnxruntime_input)\n",
        "\n",
        "# input_data = torch.randn(input_shape, dtype=torch.float32).cuda()\n",
        "output_quan_oxrun = onnx_engine_int8.run(input_data_for_inference.cpu().numpy())[0]\n",
        "\n",
        "print(f\"\\n\\nONNXRuntime [INT8] Output length: {len(output_quan_oxrun)}\")\n",
        "print(f\"ONNXRuntime [INT8] Sample output: {output_quan_oxrun}\")\n",
        "print(f\"ONNXRuntime [INT8] Sample output type: {output_quan_oxrun.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wOGwCKTFJ_V"
      },
      "source": [
        "# Homework\n",
        "ใช้ MobileNetV3 backbone แปลงโมเดลจาก Torch file to ONNX format และเร่งการทำงานโดยใช้ ONNXruntime สำหรับการอนุมานด้วยข้อมูลความละเอียดแบบ FP32, FP16, และ INT8\\\n",
        "เปรียบเทียบ FPS และ Speedup ก่อนและหลังใช้ ONNXruntime อนุมาน"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}