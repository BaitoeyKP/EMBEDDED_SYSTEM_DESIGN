{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# !pip install tensorboardX\n",
    "# from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg)\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.suptitle(\"Train vs Validation\")\n",
    "    ax1.plot(history[\"train_acc\"], label=\"Train\")\n",
    "    ax1.plot(history[\"validate_acc\"], label=\"Validation\")\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "\n",
    "    ax2.plot(history[\"train_loss\"], label=\"Train\")\n",
    "    ax2.plot(history[\"validate_loss\"], label=\"Validation\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Loss\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Conv(stride=1)-Conv(Stride=1)-Conv(Stride=1)-Pool\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import time\n",
    "\n",
    "#---Variable initialization---\n",
    "torch.manual_seed(42)\n",
    "#-----------------------------\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "#---CNN---\n",
    "class DeepModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1)  # 3x224x224 -> 10x224x224\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)  # 10x224x224 -> 10x224x224\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)  # 10x224x224 -> 10x224x224\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 10x224x224 -> 10x112x112\n",
    "        self.conv4 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1)  # 10x112x112 -> 20x112x112\n",
    "        self.conv5 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=1)  # 20x112x112 -> 20x112x112\n",
    "        self.conv6 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=1)  # 20x112x112 -> 20x112x112\n",
    "        self.fc1 = nn.Linear(20 * 56 * 56, 45)\n",
    "        self.fc2 = nn.Linear(45, 45)\n",
    "        self.fc3 = nn.Linear(45, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv3(self.conv2(self.conv1(x))))) # 3x224x224 -> 10x224x224 -> 10x112x112\n",
    "        x = self.pool(F.relu(self.conv6(self.conv5(self.conv4(x))))) # 10x112x112 -> 20x112x112 -> 20x56x56\n",
    "        x = x.view(-1, 20 * 56 * 56) #[bs, 180] (bs = Batch Size = 32 or 64 or ...)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Model init\n",
    "model = DeepModel()\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "path_save_cp = './cp/'\n",
    "best_vloss = 1_000_000.\n",
    "training_logs = {\"train_loss\": [],  \"train_acc\": [], \"validate_loss\": [], \"validate_acc\": []}\n",
    "\n",
    "t_0_nonaccelerated = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_correct = 0, 0\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.argmax(1) == labels).float().sum().item()\n",
    "\n",
    "    training_logs[\"train_loss\"].append(train_loss / len(training_loader))\n",
    "    training_logs[\"train_acc\"].append(train_correct / len(training_loader.dataset))\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    valid_loss, valid_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            valid_loss += loss_fn(voutputs, vlabels).item()\n",
    "            valid_correct += (voutputs.argmax(1) == vlabels).float().sum().item()\n",
    "        # save validation logs\n",
    "        training_logs[\"validate_loss\"].append(valid_loss / len(validation_loader))\n",
    "        training_logs[\"validate_acc\"].append(valid_correct / len(validation_loader.dataset))\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epochs {epoch+1}\".ljust(10),\n",
    "            f\"train loss {training_logs['train_loss'][-1]:.5f}\",\n",
    "            f\"train acc {training_logs['train_acc'][-1]:.5f}\",\n",
    "\n",
    "            f\"validate loss {training_logs['validate_loss'][-1]:.5f}\",\n",
    "            f\"validate acc {training_logs['validate_acc'][-1]:.5f}\",\n",
    "            )\n",
    "        print(\"-\"*80)\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if valid_loss < best_vloss:\n",
    "        best_vloss = valid_loss\n",
    "        # model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        if not os.path.exists(path_save_cp): os.mkdir(path_save_cp)\n",
    "        torch.save(model.state_dict(), path_save_cp+'best_model.pth')\n",
    "\n",
    "    epoch_number += 1\n",
    "\n",
    "t_end_nonaccelerated = time.time()-t_0_nonaccelerated\n",
    "print(f\"Time consumption for non-accelerated CUDA training (CPU only): {t_end_nonaccelerated} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(training_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference phase\n",
    "PATH = './cp/best_model.pth'\n",
    "loaded_model = DeepModel()\n",
    "loaded_model.load_state_dict(torch.load(PATH))\n",
    "acc_test = 0\n",
    "test_loss = 0\n",
    "loaded_model.eval()\n",
    "stored_lbs = stored_preds = torch.empty(0, dtype=torch.float32)\n",
    "for i, tdata in enumerate(validation_loader):\n",
    "    tinputs, tlabels = tdata\n",
    "    toutputs = loaded_model(tinputs)\n",
    "    loss = loss_fn(toutputs, tlabels)\n",
    "    test_loss += loss\n",
    "    # Argmax one-hot pred to class vector\n",
    "    _, preds_t = torch.max(toutputs, 1)\n",
    "    acc_test += (preds_t == tlabels).float().mean().item()\n",
    "    # store vec\n",
    "    stored_lbs = torch.cat((stored_lbs, tlabels), 0)\n",
    "    stored_preds = torch.cat((stored_preds, preds_t), 0)\n",
    "\n",
    "accuracy_t = round(acc_test / float(len(validation_loader)), 4)\n",
    "avg_tloss = test_loss / (i + 1)\n",
    "print('[(test loss: {}] [accuracy_test: {} %]'.format(avg_tloss, accuracy_t * 100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
